{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## [SRC](#--SRC--)\n",
    "### 1. [Preprocessing utils](#Preprocessing-utils)\n",
    "### 2. [Porfolio](#Portfolio)\n",
    "### 3. [Clustering](#Clustering)\n",
    "\n",
    "\n",
    "\n",
    "## [Scripts ](#Scripts)\n",
    "### 1. [Data preprocessing](#01.-Data-Preprocessing)\n",
    "### 2. [Main](#02.-Main)\n",
    "### 3. [Analysis](#03.-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check indices\n",
    "    - check if it's 0-based?\n",
    "    - especially when mixing slicing and indexing\n",
    "    - check if it's a mere duplicate of R code counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRC\n",
    "## Preprocessing utils\n",
    "### `src/preprocessing-utils.R` $\\rightarrow$ `src/preprocessing_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_quarter(months):\n",
    "    \"\"\"\n",
    "    월(month) 값을 분기(quarter) 값으로 전환\n",
    "    Example: (1, 2, 3, 4, 5, 6) -> (1, 1, 1, 2, 2, 2)\n",
    "    \n",
    "    INPUT:\n",
    "      x: 1 ~ 12 사이의 integer vector\n",
    "    RETURN:\n",
    "      월 -> 분기로 전환된 integer vector\n",
    "    \"\"\"\n",
    "    months = pd.to_numeric(months)\n",
    "    if not np.all(np.isin(months, np.arange(1, 13))):\n",
    "        raise ValueError(\"range of months exceeds 1~12\")\n",
    "    return (np.array(months) - 1) // 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quarter_interval(date_str):\n",
    "    \"\"\"\n",
    "    시간 변수가 날짜 형식(ex: \"20010131\")인지 \n",
    "    혹은 분기 형식(ex: \"2001/1 Quarter)인지 검사\n",
    "    \n",
    "    INPUT:\n",
    "      x: date string vector\n",
    "    RETURN:\n",
    "      날짜 형식이면 FALSE, 분기 형식이면 TRUE\n",
    "    \"\"\"\n",
    "    return len(str(date_str)) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_long(df):\n",
    "    \"\"\"\n",
    "    Short form 데이터를 long form 데이터로 변환\n",
    "    시간 변수가 날짜 형식인 경우 분기 형식으로 변환\n",
    "    \n",
    "    INPUT:\n",
    "      data: raw data를 불러들인 data frame\n",
    "    RETURN:\n",
    "      long form으로 전환된 data frame\n",
    "    \"\"\"\n",
    "    df = gather(df)\n",
    "    df.val = pd.to_numeric(df.val)\n",
    "    df = tidyup_timeframe(df, is_quarter_interval(df.time[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(df):\n",
    "    df.rename(index=str, columns={\"Unnamed: 1\": \"code\", \"Unnamed: 2\": \"name\"}, inplace=True)\n",
    "    df.columns = [\"y\"+format_quarter(str(c)) if c[0].isnumeric() else c for c in df.columns]\n",
    "    df = pd.wide_to_long(df, stubnames=\"y\", i=[\"code\", \"name\"], j=\"time\")\n",
    "    df = pd.DataFrame(df.to_records()).rename(index=str, columns={\"y\": \"val\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_quarter(string):\n",
    "    return string.replace(\" \", \"\").replace(\"/\", \"\").replace(\"Quarter\", \"\").replace(\"SemiAnnual\", \"2\").replace(\"Annual\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidyup_timeframe(df, is_quarter):\n",
    "    df.val = pd.to_numeric(df.val)\n",
    "    if is_quarter:\n",
    "        year_quarter = df.time.astype(str).str.extract('(.{4,4})(.{1,1})')\n",
    "        year_quarter.columns = [\"year\", \"quarter\"]\n",
    "        yq = year_quarter.year + \"-\" + year_quarter.quarter\n",
    "        yq.name = \"time\"\n",
    "        df = pd.concat([df.iloc[:, :2], yq, df.val], axis=1)\n",
    "    else:\n",
    "        year_quarter = df.time.astype(str).str.extract('(.{4,4})(.{2,2})')\n",
    "        year_quarter.columns = [\"year\", \"quarter\"]\n",
    "        yq = year_quarter.year + \"-\" + as_quarter(year_quarter.quarter).astype(str)\n",
    "        yq.name = \"time\"\n",
    "        df = pd.concat([df.iloc[:, :2], yq, df.val], axis=1)\n",
    "        df = pd.DataFrame(df.groupby([\"code\", \"name\", \"time\"]).mean().to_records())\n",
    "    df.sort_values(by=[\"code\", \"time\"], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, file_names, var_names, extension=\".xls\"):\n",
    "    dfs = []\n",
    "    for name in file_names:\n",
    "        print(name, end=\", \")\n",
    "        file_path = os.path.join(path, name+extension)\n",
    "        data = reshape_long( pd.read_excel(file_path, skiprows=5).iloc[1:, 1:] )\n",
    "        dfs.append(data)\n",
    "\n",
    "    vals = reduce(lambda x, y: x.merge(y, how=\"left\", on=[\"code\", \"name\", \"time\"]), dfs).iloc[:, 3:]\n",
    "    vals.columns = var_names\n",
    "    \n",
    "    features = extract_features(vals)\n",
    "    df = pd.concat([data.loc[:, [\"code\", \"time\"]], features], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(vals):\n",
    "    leverage = vals.leverage\n",
    "    asset_growth = vals.asset_growth\n",
    "    shares_turnover = vals.trade_amount / vals.stock_num\n",
    "    roa = vals.net_profit / vals.asset\n",
    "    roe = vals.net_profit / vals.equity\n",
    "    size = vals.market_cap\n",
    "    pcr = vals.pcr\n",
    "    per = vals.per\n",
    "    equity_turnover = vals.equity_turnover\n",
    "    volatility = vals.volatility\n",
    "    logret = np.log(vals.price).diff()\n",
    "    \n",
    "    features = pd.concat([leverage, asset_growth, shares_turnover, roa, roe, size, \n",
    "                          pcr, per, equity_turnover, volatility, logret], axis=1)\n",
    "    features.columns = [\"leverage\", \"asset_growth\", \"shares_turnover\", \"roa\", \"roe\", \"size\", \n",
    "                        \"pcr\", \"per\", \"equity_turnover\", \"volatility\", \"logret\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio\n",
    "### `src/functions-portfolio.R` $\\rightarrow$ `src/portfolio.py`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip3 install quadprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quadprog import solve_qp\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x, method, risk_free=None):\n",
    "    n_cluster = x.shape[1]\n",
    "    zeros = np.zeros(n_cluster).T\n",
    "    \n",
    "    if method == \"GMV\":\n",
    "        A = np.c_[np.ones(n_cluster), np.diag(np.ones(n_cluster))]\n",
    "        b = np.array([1] + [0]*n_cluster, dtype=np.float64)\n",
    "    elif method == \"Tangency\":\n",
    "        if not risk_free:\n",
    "            raise ValueError(\"method is 'Tangency'. 'risk_free' should not be None\")\n",
    "        rf = risk_free.r.mean()\n",
    "        A = np.c_[x.mean() - rf, np.diag([1] * n_cluster)]\n",
    "        b = np.array([(x.mean() - rf).sum(), [0] * n_cluster], dtype=np.float64)\n",
    "    else:\n",
    "        raise ValueError(\"invalid method\")\n",
    "    \n",
    "    qp = solve_qp(x.cov().to_numpy(), zeros, A, b, meq=1)\n",
    "    return qp[0]   # solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio_return(data, timeset, n_time, with_, method,\n",
    "                         market, risk_free, random_state=0):\n",
    "    p_return = []\n",
    "    for c_time in timeset:\n",
    "        time_idx = np.arange((c_time-n_time), c_time+1)\n",
    "        c_return = get_cluster_return(data, time_idx, with_, market, risk_free)\n",
    "        \n",
    "        x = c_return.x[:-1]\n",
    "        y = c_return.y[:-1]\n",
    "        \n",
    "        weight = get_weight(x, method, risk_free.iloc[time_idx, :])\n",
    "        p_return.append(integrate_return(y, weight))\n",
    "        \n",
    "    return np.array(p_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid_py(*itrs):\n",
    "    prod = list(product(*itrs))\n",
    "    expanded = {'Var{}'.format(i+1): [x[i] for x in prod] for i in range(len(itrs))}\n",
    "    return pd.DataFrame(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(*args):\n",
    "    # all possible combinations of *args\n",
    "    grd = expand_grid_py(*args)\n",
    "    grd.sort_values(by=grd.columns, inplace=True)\n",
    "    return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(data, market, risk_free, start, end,\n",
    "                       with_list, n_time_list, method_list, random_state):\n",
    "    timeset = data.time.unique()\n",
    "    st = [i for i, t in enumerate(timeset) if start in t][0]\n",
    "    en = [i for i, t in enumerate(timeset) if end in t][0]\n",
    "    timeset = timeset[st:en]\n",
    "    \n",
    "    # Model grid\n",
    "    grd = expand_grid(with_list, n_time_list, method_list)\n",
    "    grd.columns = [\"with\", \"n_time\", \"method\"]\n",
    "    \n",
    "    n_each = grd.shape[0] // 3\n",
    "    indices = np.repeat([\"_1\", \"_2\", \"_3\"], n_each)\n",
    "    model_names = np.core.defchararray.add(grd.iloc[:, 0].to_numpy(), indices)\n",
    "    \n",
    "    # Portfolio returns table\n",
    "    pr_tbl = kospi.iloc[timeset, :]\n",
    "    pr_tbl.columns = [\"time\", \"kospi\"]\n",
    "    \n",
    "    print(f\"from {start} to {end}\")\n",
    "    \n",
    "    for with_ in with_list:\n",
    "        for n_time in n_time_list:\n",
    "            for method in method_list:\n",
    "                print(f\"  with: {with_}\")\n",
    "                print(f\"  n_time: {n_time}\")\n",
    "                print(f\"  method: {method}\")\n",
    "                \n",
    "                pr = get_portfolio_return(data, timeset, n_time, with_, method, market, risk_free)\n",
    "                pr_tbl = pd.concat([pr_tbl, pr], axis=1)\n",
    "                pr_tbl.columns = list(pr_tbl.columns[:-1]) [\"pr\"]\n",
    "    \n",
    "    pr_tbl.columns = [\"time\", \"kospi\"] + model_names.tolist()\n",
    "    \n",
    "    # Model performance summary\n",
    "    pr_cumsum = pr_tbl.iloc[:, 2:].cumsum().iloc[-1, :]\n",
    "    pr_sd = np.diag(np.sqrt(pr_tbl.iloc[:, 2:].cov()))\n",
    "    pr_info_rate = pr_tbl.iloc[:, 2:].to_numpy() - pr_tbl.iloc[:, 1].to_numpy()[np.newaxis].T\n",
    "    pr_info_rate = pr_info_rate.mean(axis=0) / pr_info_rate.std(axis=0)\n",
    "    \n",
    "    summ = pd.concat([grd, pr_cumsum, pr_sd, pr_info_rate], axis=1)\n",
    "    summ.columns = grd.columns.tolist() + [\"cumsum\", \"sd\", \"info_r\"]\n",
    "    \n",
    "    return {\"return\": pr_tbl, \"summary\": summ}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "help(solve_qp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* `Python`: Minimize $1/2 x^T G x - a^T x$, Subject to $C^T x >= b$.\n",
    "* `R`: $min(−d^Tb+1/2b^TDb)$ with the constraints $A^Tb>=b_0$."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.columns.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd = iris.head().iloc[:, :-1]\n",
    "ff = iris.head().iloc[:, :-1].iloc[:, 2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.to_numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ff.to_numpy()[np.newaxis].T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.to_numpy() - ff.to_numpy()[np.newaxis].T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.diag(np.sqrt(iris.cov()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cumsum_pr_tbl(col):\n",
    "    return col.cumsum()\n",
    "    \n",
    "iris.apply(cumsum_pr_tbl, axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(dd.columns[:-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.random.randn(10).tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = np.array([1,2,3], dtype=str)\n",
    "b = np.array([\"a\", \"b\", \"c\"], dtype=str)\n",
    "np.core.defchararray.add(a, b)\n",
    "\n",
    "np.repeat([\"_1\", \"_2\", \"_3\"], 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = [1, 2]\n",
    "b = [\"a\", \"b\"]\n",
    "dd = expand_grid_py(a, b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_cluster = xx.shape[1]\n",
    "qp = solve_qp(xx.cov().to_numpy(), np.zeros(n_cluster).T, \n",
    "              np.c_[np.ones(n_cluster), np.diag(np.ones(n_cluster))],\n",
    "              np.array([1] + [0]*n_cluster, dtype=np.float64), meq=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qp[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xx = x.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xx.cov()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_cluster = 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.c_[ np.ones(3), np.diag(np.ones(n_cluster)) ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.array([1] + [0]*n_cluster)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.array([np.exp(dd)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### `src/functions-clustering.R` $\\rightarrow$ `src/clustering.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_slice(data, time_idx):\n",
    "    as_list = list(time_idx)\n",
    "    return stock_tbl.groupby([\"code\"]).nth(as_list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_expand(data, skip=[0,1]):\n",
    "    cols = [col for col in range(data.shape[1]) if col not in skip]\n",
    "    \n",
    "    while len(set(data.time)) > 1:\n",
    "        lagged = data.iloc[:, cols].shift(1)\n",
    "        lagged.columns = [f\"x{c}\" for c in cols]\n",
    "        \n",
    "        data = pd.concat([data, lagged], axis=1)\n",
    "        data = data.groupby([\"code\"], as_index=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
    "        \n",
    "        cols = np.array(cols) + len(cols)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tbl(data, skip=[0,1]):\n",
    "    idx = [i for i in range(data.shape[1]) if i not in skip]\n",
    "    vals = data.iloc[:, idx]\n",
    "    data.iloc[:, idx] = (vals - vals.mean()) / vals.std()\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA에서 데이터 손실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_(data, skip=[0,1], threshold=.8):\n",
    "    \"\"\"\n",
    "    데이터에 PCA(주성분분석)을 수행한다.\n",
    "    \n",
    "    INPUT:\n",
    "      data: data frame\n",
    "      skip: PCA 대상에서 제외할 열 번호 (integer vector)\n",
    "      threshold: 주성분 개수 선택의 기준이 되는 변동의 비율 (0 ~ 1)\n",
    "    \n",
    "    RETURN:\n",
    "      변수들이 주성분으로 대체된 data frame\n",
    "    \"\"\"\n",
    "    idx = [i for i in range(data.shape[1]) if i not in skip]\n",
    "    omit_na = data.iloc[:, idx].dropna()    #### 여기 dropna() 때문에 데이터 절반이 날아감\n",
    "    \n",
    "    pca = PCA()\n",
    "    x_pc = pd.DataFrame(pca.fit_transform(omit_na))\n",
    "    n_pc = np.where(pca.explained_variance_ratio_.cumsum() > threshold)[0][0] + 1\n",
    "    x_pc = x_pc.iloc[:, :n_pc]\n",
    "    x_pc.columns = [f\"PC{c+1}\" for c in x_pc.columns]\n",
    "    \n",
    "    df_pc = pd.concat([data.dropna().iloc[:, skip].reset_index(drop=True), x_pc], axis=1)\n",
    "    return df_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_factors_residual(data, risk_free):\n",
    "    idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "    risk_free = risk_free.iloc[idx_rf, :]\n",
    "    \n",
    "    for code in tqdm(data.code.unique()):\n",
    "        data.loc[data.code == code, \"logret\"] = data[data.code == code][\"logret\"].shift(-1)\n",
    "        data.loc[data.code == code, \"rf\"] = risk_free.r.shift(-1)\n",
    "    \n",
    "    y = data.logret - data.rf\n",
    "    x = pca_(data.drop(['logret', 'rf'], axis=1))\n",
    "    \n",
    "    df_pca = pd.concat([x, y], axis=1).iloc[:, 2:]\n",
    "    df_pca.rename(index=str, columns={0: \"y\"}, inplace=True)\n",
    "    fml = \" + \".join([c for c in df_pca.columns if \"PC\" in c])\n",
    "    lmfit = sm.OLS.from_formula(f\"y ~ {fml}\", data=df_pca).fit()\n",
    "    \n",
    "    yhat = lmfit.predict(x)\n",
    "    res = y - yhat\n",
    "    data[\"factors_res\"] = (res - res.mean()) / res.std()\n",
    "    \n",
    "    n_time = data.time.unique().shape[0]\n",
    "    dfs = [data.loc[data.code == code, :].iloc[:-1, :] for code in tqdm(data.code.unique())]\n",
    "    data = pd.concat(dfs)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_market_residual(data, market, risk_free):\n",
    "    idx_mk = [True if t in data.time.tolist() else False for t in market.time]\n",
    "    market = market.iloc[idx_mk, :]\n",
    "    \n",
    "    idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "    risk_free = risk_free.iloc[idx_rf, :]\n",
    "    \n",
    "    for code in tqdm(data.code.unique()):\n",
    "        data.loc[data.code == code, \"mk\"] = market.logret\n",
    "        data.loc[data.code == code, \"rf\"] = risk_free.r\n",
    "        y = data.logret - data.rf\n",
    "        x = data.mk - data.rf\n",
    "    \n",
    "    lmfit = sm.OLS.from_formula(\"y ~ x\", data=data).fit()\n",
    "    yhat = lmfit.predict(lmfit)\n",
    "    res = y - yhat\n",
    "    data[\"market_res\"] = (res - res.mean()) / res.std()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp(x, k, random_state=0):\n",
    "    #n = x.shape[0]\n",
    "    #centers = [0] * k\n",
    "    #centers[0] = np.random.randint(1, n+1)\n",
    "    #\n",
    "    #L2_mat = pd.DataFrame(squareform(pdist(x.iloc[:, 1:])), columns=x.index.unique(), index=x.index.unique())\n",
    "    #L2_mat = L2_mat ** 2\n",
    "    #\n",
    "    #for i in range(1, k):\n",
    "    #    weight = l2.iloc[:, centers].apply(np.min, axis=1)\n",
    "    #    centers[i] = np.random.choice(range(1, n+1), p=weight/weight.sum())\n",
    "    return KMeans(n_clusters=k, random_state=random_state).fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dunn index 대신 silhouette score를 사용\n",
    "* 속도 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_tbl(data, ncmin=2, ncmax=5):\n",
    "    data = data.dropna()\n",
    "    \n",
    "    ncs = range(ncmin, nvmax)\n",
    "    \n",
    "    X = data.iloc[:, 2:]\n",
    "    models = [kmeanspp(X, nc) for nc in ncs]\n",
    "    silhouettes = np.array([silhouette_score(X, m.labels_) for m in tqdm(models)])\n",
    "    best_model = models[silhouettes.argmax()]\n",
    "    \n",
    "    return pd.DataFrame(np.array([data.code.unique(), kmeans.labels_]).T, columns=[\"code\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_with(data, with_, market, risk_free):\n",
    "    if with_ == \"return\":\n",
    "        return data.loc[:, [\"code\", \"time\", \"logret\"]]\n",
    "    elif with_ == \"market_residual\":\n",
    "        return add_market_residual(data, market, risk_free).loc[:, [\"code\", \"time\", \"market_res\"]]\n",
    "    elif with_ == \"factors\":\n",
    "        return pca_(data.drop([\"logret\"], axis=1))\n",
    "    elif with_ == \"factors_residual\":\n",
    "        return add_factors_residual(data, risk_free).loc[:, [\"code\", \"time\", \"factors_res\"]]\n",
    "    else:\n",
    "        raise ValueError(\"'with_' should be one of ['return', 'market_residual', 'factors', 'factors_residual']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_return(return_, weight):\n",
    "    weight = np.array(weight)\n",
    "    weight = weight / weight.sum()\n",
    "    return np.log(np.sum(weight * np.exp(return_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_return_apply(row):\n",
    "    return integrate_return(row[\"logret\"], row[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_return(data, time_idx, with_, market, risk_free):\n",
    "    cluster_df = time_slice(data, time_idx)\n",
    "    cluster_df = scale_tbl(cluster_df)\n",
    "    cluster_df = kmeans_with(with_, market, risk_free)\n",
    "    cluster_df = time_expand(cluster_df)\n",
    "    cluster_df = get_kmeans_tbl(cluster_df)\n",
    "    \n",
    "    data = data.merge(cluster_df, how=\"left\", on=[\"code\"]).loc[:, [\"code\", \"time\", \"logret\", \"size\", \"cluster\"]]\n",
    "    data[\"size\"] = data.size.shift(1)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    data[\"logret\"] = data.groupby([\"cluster\", \"time\"]).apply(integrate_return_apply).reset_index(drop=True)\n",
    "    data = pd.DataFrame(pd.pivot_table(data, values='logret', index=['cluster']).T.to_records()).iloc[:, 1:]\n",
    "    data.columns = [f\"time{c}\" for c in data.columns]\n",
    "    data = data.T[0]\n",
    "    \n",
    "    x = data[time_idx]\n",
    "    y = data[time_idx[-1] + 1]\n",
    "    y_time = data.index[time_idx[-1] + 1]\n",
    "    \n",
    "    if (x.shape[0] == len(time_idx)) and (y_time == data.time.unique()[time_idx[-1]+1]):\n",
    "        return {\"x\": x, \"y\": y}\n",
    "    else:\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd = pd.DataFrame(pd.pivot_table(data, values='logret', index=['time']).T.to_records()).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd = dd.T[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.index[5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd[5:10].shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.random.randn(10).argmax()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "silhouette_score(x.iloc[:, 2:], kmeans.labels_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = pd.DataFrame([[12.654, 32.530],\n",
    "     [15.500, 12.334],\n",
    "     [14.364, 25.840],\n",
    "     [25.510, 32.224],\n",
    "     [17.636, 15.740]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l2 = pd.DataFrame(squareform(pdist(a.iloc[:, 1:])), columns=a.index.unique(), index=a.index.unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l2**2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stock_tbl = pd.read_csv(\"data/processed/stock.csv\")\n",
    "kospi = pd.read_csv(\"data/processed/kospi.csv\")\n",
    "risk_free = pd.read_csv(\"data/processed/risk_free.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = scale_tbl(stock_tbl.copy())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "risk_free = risk_free.iloc[idx_rf, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for code in tqdm(data.code.unique()):\n",
    "    data.loc[data.code == code, \"logret\"] = data[data.code == code][\"logret\"].shift(-1)\n",
    "    data.loc[data.code == code, \"rf\"] = risk_free.r.shift(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = data.logret - data.rf\n",
    "x = pca_(data.drop(['logret', 'rf'], axis=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_pca = pd.concat([x, y], axis=1).iloc[:, 2:]\n",
    "df_pca.rename(index=str, columns={0: \"y\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fml = \" + \".join([c for c in df_pca.columns if \"PC\" in c])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lmfit = sm.OLS.from_formula(f\"y ~ {fml}\", data=df_pca).fit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "yhat = lmfit.predict(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = y - yhat\n",
    "data[\"factors_res\"] = (res - res.mean()) / res.std()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_time = data.time.unique().shape[0]\n",
    "n_time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfs = [data.loc[data.code == code, :].iloc[:-1, :] for code in tqdm(data.code.unique())]\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pca(scale_tbl(stock_tbl))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vals.mean(), vals.std()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = stock_tbl.copy().head().iloc[:, :5]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "time_expand(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skip = [0,1]\n",
    "cols = [col for col in range(data.shape[1]) if col not in skip]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lagged = data.iloc[:, cols].shift(1)\n",
    "lagged.columns = [f\"x{c}\" for c in cols]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = pd.concat([data, lagged], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(set(stock_tbl.time))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "stock_tbl.groupby([\"code\"]).nth([1,2,3]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts\n",
    "## 01. Data Preprocessing\n",
    "### `scripts/01_data-preprocessing.R` $\\rightarrow$ `scripts/preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data\", \"raw\")\n",
    "file_names = [\"asset\", \"asset-growth\", \"equity\", \"equity-turnover\",\n",
    "              \"leverage\", \"market-cap\", \"net-profit\", \"pcr\", \"per\",\n",
    "              \"stock-number\", \"stock-price\", \"trade-amount\", \"volatility\"]\n",
    "var_names = [\"asset\", \"asset_growth\", \"equity\", \"equity_turnover\",\n",
    "             \"leverage\", \"market_cap\", \"net_profit\", \"pcr\", \"per\",\n",
    "             \"stock_num\", \"price\", \"trade_amount\", \"volatility\"]\n",
    "extension = \".xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asset, asset-growth, equity, equity-turnover, leverage, market-cap, net-profit, pcr, per, stock-number, stock-price, trade-amount, volatility, "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>time</th>\n",
       "      <th>leverage</th>\n",
       "      <th>asset_growth</th>\n",
       "      <th>shares_turnover</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>size</th>\n",
       "      <th>pcr</th>\n",
       "      <th>per</th>\n",
       "      <th>equity_turnover</th>\n",
       "      <th>volatility</th>\n",
       "      <th>logret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.850400e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.586667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.255281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-2</td>\n",
       "      <td>206.92</td>\n",
       "      <td>23.60</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>1.104880e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.053333</td>\n",
       "      <td>2.22</td>\n",
       "      <td>62.004616</td>\n",
       "      <td>0.235505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.087867e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.543333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.334550</td>\n",
       "      <td>-0.040738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-4</td>\n",
       "      <td>324.23</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>4.613333e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.346667</td>\n",
       "      <td>2.89</td>\n",
       "      <td>62.702979</td>\n",
       "      <td>-0.847219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000020</td>\n",
       "      <td>1998-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.973333e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.726084</td>\n",
       "      <td>0.120535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code    time  leverage  asset_growth  shares_turnover       roa  \\\n",
       "0  000020  1997-1       NaN           NaN         0.006314       NaN   \n",
       "1  000020  1997-2    206.92         23.60         0.015739  0.002507   \n",
       "2  000020  1997-3       NaN           NaN         0.004035       NaN   \n",
       "3  000020  1997-4    324.23         12.41         0.004633  0.009214   \n",
       "4  000020  1998-1       NaN           NaN         0.012191       NaN   \n",
       "\n",
       "        roe          size  pcr        per  equity_turnover  volatility  \\\n",
       "0       NaN  8.850400e+10  NaN  15.586667              NaN   60.255281   \n",
       "1  0.007696  1.104880e+11  NaN  11.053333             2.22   62.004616   \n",
       "2       NaN  1.087867e+11  NaN  10.543333              NaN   56.334550   \n",
       "3  0.039088  4.613333e+10  NaN   4.346667             2.89   62.702979   \n",
       "4       NaN  5.973333e+10  NaN   4.750000              NaN   73.726084   \n",
       "\n",
       "     logret  \n",
       "0       NaN  \n",
       "1  0.235505  \n",
       "2 -0.040738  \n",
       "3 -0.847219  \n",
       "4  0.120535  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tbl = preprocess(path, file_names, var_names, extension=\".xls\")\n",
    "stock_tbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KOSPI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_df(df):\n",
    "    df = df.reset_index()\n",
    "    df[\"time\"] = df[['time', 'level_1']].astype(str).apply(lambda x: '-'.join(x), axis=1)\n",
    "    df = pd.concat([df.time, df.price], axis=1)\n",
    "    df.columns = [\"time\", \"logret\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>logret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-2</td>\n",
       "      <td>0.082477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-3</td>\n",
       "      <td>-0.064037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-4</td>\n",
       "      <td>-0.499768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-1</td>\n",
       "      <td>0.247514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time    logret\n",
       "0  1997-1       NaN\n",
       "1  1997-2  0.082477\n",
       "2  1997-3 -0.064037\n",
       "3  1997-4 -0.499768\n",
       "4  1998-1  0.247514"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi = pd.read_excel(\"data/raw/kospi-index.xlsx\", names=[\"time\", \"price\"])\n",
    "g = kospi.groupby([pd.DatetimeIndex(kospi.time).year, as_quarter(pd.DatetimeIndex(kospi.time).month)])\n",
    "g = np.log(g.mean()).diff()\n",
    "kospi = unpack_df(g)\n",
    "kospi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk-free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-1</td>\n",
       "      <td>0.119707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-2</td>\n",
       "      <td>0.118287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-3</td>\n",
       "      <td>0.119115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-4</td>\n",
       "      <td>0.145110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-1</td>\n",
       "      <td>0.204599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time         r\n",
       "0  1997-1  0.119707\n",
       "1  1997-2  0.118287\n",
       "2  1997-3  0.119115\n",
       "3  1997-4  0.145110\n",
       "4  1998-1  0.204599"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_free = pd.read_excel(\"data/raw/cd-risk-free.xlsx\", names=[\"time\", \"r\"])\n",
    "risk_free.time = risk_free.time.str.replace(\"/\", \"-\").str.split().str[0]\n",
    "risk_free.r = np.log(1 + risk_free.r / 100)\n",
    "risk_free.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.mkdir(\"data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tbl.to_csv(\"data/processed/stock2.csv\", index=False)\n",
    "kospi.to_csv(\"data/processed/kospi2.csv\", index=False)\n",
    "risk_free.to_csv(\"data/processed/risk_free2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Main\n",
    "### `scripts/02_main.R` $\\rightarrow$ `scripts/main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.clustering import *\n",
    "from src.portfolio import *\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tbl = pd.read_csv(\"data/processed/stock.csv\")\n",
    "kospi = pd.read_csv(\"data/processed/kospi.csv\")\n",
    "risk_free = pd.read_csv(\"data/processed/risk_free.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_list = [\n",
    "    #\"return\", \n",
    "    \"market_residual\", \n",
    "    #\"factors\", \n",
    "    #\"factors_residual\"\n",
    "]\n",
    "n_time_list = [\n",
    "    6, 8, \n",
    "    #10, 12\n",
    "]\n",
    "method_list = [\n",
    "    \"GMV\", #\"Tangency\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 2002-4 to 2005-3\n",
      "  with: market_residual\n",
      "  n_time: 6\n",
      "  method: GMV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:25<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  with: market_residual\n",
      "  n_time: 8\n",
      "  method: GMV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:41<00:00,  8.68s/it]\n"
     ]
    }
   ],
   "source": [
    "start_list = [\"2002-4\", ]#\"2005-4\", \"2008-4\", \"2011-4\"]\n",
    "end_list = [\"2005-3\", ]#\"2008-3\", \"2011-3\", \"2014-3\"]\n",
    "valid_res = []\n",
    "\n",
    "for st, en in zip(start_list, end_list):\n",
    "    valid_res.append(evaluate_portfolio(stock_tbl, kospi, risk_free, st, en,\n",
    "                                        with_list, n_time_list, method_list, \n",
    "                                        random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>kospi</th>\n",
       "      <th>market_residual_6_GMV</th>\n",
       "      <th>market_residual_8_GMV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-4</td>\n",
       "      <td>-0.043557</td>\n",
       "      <td>-0.182029</td>\n",
       "      <td>-0.168141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>-0.166381</td>\n",
       "      <td>0.150088</td>\n",
       "      <td>0.133076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>0.033397</td>\n",
       "      <td>0.123056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.120947</td>\n",
       "      <td>0.070731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.096017</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.015975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time     kospi  market_residual_6_GMV  market_residual_8_GMV\n",
       "0  2002-4 -0.043557              -0.182029              -0.168141\n",
       "1  2003-1 -0.166381               0.150088               0.133076\n",
       "2  2003-2  0.110888               0.033397               0.123056\n",
       "3  2003-3  0.131688               0.120947               0.070731\n",
       "4  2003-4  0.096017               0.013463               0.015975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[0][\"return\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with</th>\n",
       "      <th>n_time</th>\n",
       "      <th>method</th>\n",
       "      <th>cumsum</th>\n",
       "      <th>sd</th>\n",
       "      <th>info_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>market_residual_6_GMV</th>\n",
       "      <td>market_residual</td>\n",
       "      <td>6</td>\n",
       "      <td>GMV</td>\n",
       "      <td>0.683359</td>\n",
       "      <td>0.095750</td>\n",
       "      <td>0.127044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_residual_8_GMV</th>\n",
       "      <td>market_residual</td>\n",
       "      <td>8</td>\n",
       "      <td>GMV</td>\n",
       "      <td>0.496945</td>\n",
       "      <td>0.098431</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  with  n_time method    cumsum        sd  \\\n",
       "market_residual_6_GMV  market_residual       6    GMV  0.683359  0.095750   \n",
       "market_residual_8_GMV  market_residual       8    GMV  0.496945  0.098431   \n",
       "\n",
       "                         info_r  \n",
       "market_residual_6_GMV  0.127044  \n",
       "market_residual_8_GMV  0.006877  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[0][\"summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 2014-4 to 2017-3\n",
      "  with: market_residual\n",
      "  n_time: 6\n",
      "  method: GMV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:24<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  with: market_residual\n",
      "  n_time: 8\n",
      "  method: GMV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:35<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "start = \"2014-4\"\n",
    "end = \"2017-3\"\n",
    "\n",
    "test_res = evaluate_portfolio(stock_tbl, kospi, risk_free, start, end,\n",
    "                              with_list, n_time_list, method_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs directory already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"outputs\")\n",
    "except OSError:\n",
    "    print(\"outputs directory already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/valid_res_list.pickle\", \"wb\") as wb:\n",
    "    pickle.dump(valid_res, wb)\n",
    "with open(\"outputs/test_res.pickle\", \"wb\") as wb:\n",
    "    pickle.dump(test_res, wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Analysis\n",
    "### `scripts/03_analysis.R` $\\rightarrow$ `scripts/analysis.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/valid_res_list.pickle\", \"rb\") as rb:\n",
    "    valid_res = pickle.load(rb)\n",
    "with open(\"outputs/test_res.pickle\", \"rb\") as rb:\n",
    "    test_res = pickle.load(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeset = stock_tbl.time.unique()\n",
    "stst = [i for i, t in enumerate(timeset) if st in t][0]\n",
    "enen = [i for i, t in enumerate(timeset) if en in t][0]\n",
    "timeset = list(range(stst, enen+1))\n",
    "timeset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2002-4', '2003-1', '2003-2', '2003-3', '2003-4', '2004-1',\n",
       "       '2004-2', '2004-3', '2004-4', '2005-1', '2005-2', '2005-3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tbl.time.unique()[timeset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 19 20 21 22 23]\n"
     ]
    }
   ],
   "source": [
    "for c_time in timeset:\n",
    "    print(np.arange(c_time-6+1, c_time+1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_idx = [18, 19, 20, 21, 22, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factors</td>\n",
       "      <td>6</td>\n",
       "      <td>GMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>factors</td>\n",
       "      <td>6</td>\n",
       "      <td>Tangency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factors</td>\n",
       "      <td>8</td>\n",
       "      <td>GMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>factors</td>\n",
       "      <td>8</td>\n",
       "      <td>Tangency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factors</td>\n",
       "      <td>10</td>\n",
       "      <td>GMV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Var1  Var2      Var3\n",
       "0  factors     6       GMV\n",
       "1  factors     6  Tangency\n",
       "2  factors     8       GMV\n",
       "3  factors     8  Tangency\n",
       "4  factors    10       GMV"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = expand_grid(with_list, n_time_list, method_list)\n",
    "grd.reset_index(drop=True, inplace=True)\n",
    "grd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = reduce(lambda x, y: x.map(str) + \"_\" + y.map(str), [grd[c] for c in grd.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086208</td>\n",
       "      <td>0.772396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.905268</td>\n",
       "      <td>-0.804845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.118142</td>\n",
       "      <td>-1.227595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.983959</td>\n",
       "      <td>-0.827903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.463692</td>\n",
       "      <td>-0.443045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.083735</td>\n",
       "      <td>-0.218963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.708171</td>\n",
       "      <td>0.635759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.306383</td>\n",
       "      <td>1.402967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.389463</td>\n",
       "      <td>2.332261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.230438</td>\n",
       "      <td>0.932226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         0         1\n",
       "0 -0.086208  0.772396       NaN       NaN\n",
       "1 -1.905268 -0.804845       NaN       NaN\n",
       "2  1.118142 -1.227595       NaN       NaN\n",
       "3 -0.983959 -0.827903       NaN       NaN\n",
       "4 -0.463692 -0.443045       NaN       NaN\n",
       "5       NaN       NaN  2.083735 -0.218963\n",
       "6       NaN       NaN -0.708171  0.635759\n",
       "7       NaN       NaN -0.306383  1.402967\n",
       "8       NaN       NaN -0.389463  2.332261\n",
       "9       NaN       NaN -0.230438  0.932226"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(10).reshape(5,2), index=[0,1,2,3,4])\n",
    "df2 = pd.DataFrame(np.random.randn(10).reshape(5,2), index=[5,6,7,8,9])\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'market_residual'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = time_slice(stock_tbl, time_idx)\n",
    "cluster_df = scale_tbl(cluster_df)\n",
    "#cluster_df = kmeans_with(cluster_df, with_list[1], kospi, risk_free)\n",
    "#cluster_df = time_expand(cluster_df)\n",
    "#cluster_df = get_kmeans_tbl(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = cluster_df.copy()\n",
    "\n",
    "idx_mk = [True if t in data.time.tolist() else False for t in kospi.time]\n",
    "market = kospi.iloc[idx_mk, :]\n",
    "\n",
    "idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "rf = risk_free.iloc[idx_rf, :]\n",
    "\n",
    "for code in data.code.unique():\n",
    "    data.loc[data.code == code, \"mk\"] = market.logret.to_numpy()\n",
    "    data.loc[data.code == code, \"rf\"] = rf.r.to_numpy()\n",
    "data[\"y\"] = data.logret - data.rf\n",
    "data[\"x\"] = data.mk - data.rf\n",
    "\n",
    "lmfit = sm.OLS.from_formula(\"y ~ x\", data=data).fit()\n",
    "yhat = lmfit.predict(data[\"x\"])\n",
    "res = data.y.to_numpy() - yhat\n",
    "\n",
    "data[\"market_res\"] = (res - res.mean()) / res.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stock_tbl.merge(cluster_df, how=\"left\", on=[\"code\"]).loc[:, [\"code\", \"time\", \"logret\", \"size\", \"cluster\"]]\n",
    "data[\"size\"] = data[\"size\"].shift(1)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.cluster = data.cluster.astype(int)\n",
    "\n",
    "data = pd.DataFrame(data.groupby([\"cluster\", \"time\"]).apply(integrate_return_apply), columns=[\"logret\"]).reset_index()\n",
    "pivot = pd.pivot_table(data, values='logret', index=['cluster'], columns=['time']).T\n",
    "data = pd.DataFrame(pivot.to_records()).iloc[:, 1:]\n",
    "data.columns = [f\"cluster{int(c)+1}\" for c in data.columns]\n",
    "data = pd.concat([pd.Series(pivot.index), data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = data.iloc[time_idx, :].reset_index(drop=True)\n",
    "yy = data.iloc[time_idx[-1] + 1, :]\n",
    "y_time = data.time[time_idx[-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xx.iloc[:, 1:].reset_index(drop=True)\n",
    "y = yy[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = x.shape[1]\n",
    "zeros = np.zeros(n_cluster).T\n",
    "\n",
    "A = np.c_[np.ones(n_cluster), np.diag(np.ones(n_cluster))]\n",
    "b = np.array([1] + [0]*n_cluster, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = solve_qp(x.cov().to_numpy(), zeros, A, b, meq=1)\n",
    "weight = qp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array(weight)\n",
    "w = w / w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate_return(y, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = valid_res[0][\"return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = pd.concat([rr.iloc[12:, :2].reset_index(drop=True), rr.iloc[:12, 2:].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_cumsum = pr_tbl.iloc[:, 2:].cumsum().iloc[-1, :]\n",
    "df_index = pr_cumsum.index\n",
    "pr_cumsum.reset_index(drop=True, inplace=True)\n",
    "pr_sd = np.diag(np.sqrt(pr_tbl.iloc[:, 2:].cov()))\n",
    "pr_info_rate = pr_tbl.iloc[:, 2:].to_numpy() - pr_tbl.iloc[:, 1].to_numpy()[np.newaxis].T\n",
    "pr_info_rate = pr_info_rate.mean(axis=0) / pr_info_rate.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = expand_grid(with_list, n_time_list, method_list)\n",
    "grd.reset_index(drop=True, inplace=True)\n",
    "grd.columns = [\"with\", \"n_time\", \"method\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = pd.concat([grd] + [pd.Series(x) for x in [pr_cumsum, pr_sd, pr_info_rate]], axis=1)\n",
    "summ.columns = grd.columns.tolist() + [\"cumsum\", \"sd\", \"info_r\"]\n",
    "summ.index = df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with</th>\n",
       "      <th>n_time</th>\n",
       "      <th>method</th>\n",
       "      <th>cumsum</th>\n",
       "      <th>sd</th>\n",
       "      <th>info_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>market_residual_6_GMV</th>\n",
       "      <td>market_residual</td>\n",
       "      <td>6</td>\n",
       "      <td>GMV</td>\n",
       "      <td>0.479461</td>\n",
       "      <td>0.096741</td>\n",
       "      <td>-0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_residual_8_GMV</th>\n",
       "      <td>market_residual</td>\n",
       "      <td>8</td>\n",
       "      <td>GMV</td>\n",
       "      <td>0.562124</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.047305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  with  n_time method    cumsum        sd  \\\n",
       "market_residual_6_GMV  market_residual       6    GMV  0.479461  0.096741   \n",
       "market_residual_8_GMV  market_residual       8    GMV  0.562124  0.100113   \n",
       "\n",
       "                         info_r  \n",
       "market_residual_6_GMV -0.004129  \n",
       "market_residual_8_GMV  0.047305  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
