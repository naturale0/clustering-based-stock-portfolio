{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "## 1. [Data-Preprocessing](#Data-Preprocessing)\n",
    "## 2. [Porfolio](#Portfolio**)\n",
    "## 3. [Clustering](#Clustering)\n",
    "## ?. [Main Script](#Main-script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `src/preprocessing-utils.R` $\\rightarrow$ `src/preprocessing_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_quarter(months):\n",
    "    \"\"\"\n",
    "    월(month) 값을 분기(quarter) 값으로 전환\n",
    "    Example: (1, 2, 3, 4, 5, 6) -> (1, 1, 1, 2, 2, 2)\n",
    "    \n",
    "    INPUT:\n",
    "      x: 1 ~ 12 사이의 integer vector\n",
    "    RETURN:\n",
    "      월 -> 분기로 전환된 integer vector\n",
    "    \"\"\"\n",
    "    months = pd.to_numeric(months)\n",
    "    if not np.all(np.isin(months, np.arange(1, 13))):\n",
    "        raise ValueError(\"range of months exceeds 1~12\")\n",
    "    return (np.array(months) - 1) // 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quarter_interval(date_str):\n",
    "    \"\"\"\n",
    "    시간 변수가 날짜 형식(ex: \"20010131\")인지 \n",
    "    혹은 분기 형식(ex: \"2001/1 Quarter)인지 검사\n",
    "    \n",
    "    INPUT:\n",
    "      x: date string vector\n",
    "    RETURN:\n",
    "      날짜 형식이면 FALSE, 분기 형식이면 TRUE\n",
    "    \"\"\"\n",
    "    return len(str(date_str)) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_long(df):\n",
    "    \"\"\"\n",
    "    Short form 데이터를 long form 데이터로 변환\n",
    "    시간 변수가 날짜 형식인 경우 분기 형식으로 변환\n",
    "    \n",
    "    INPUT:\n",
    "      data: raw data를 불러들인 data frame\n",
    "    RETURN:\n",
    "      long form으로 전환된 data frame\n",
    "    \"\"\"\n",
    "    df = gather(df)\n",
    "    df.val = pd.to_numeric(df.val)\n",
    "    df = tidyup_timeframe(df, is_quarter_interval(df.time[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(df):\n",
    "    df.rename(index=str, columns={\"Unnamed: 1\": \"code\", \"Unnamed: 2\": \"name\"}, inplace=True)\n",
    "    df.columns = [\"y\"+format_quarter(str(c)) if c[0].isnumeric() else c for c in df.columns]\n",
    "    df = pd.wide_to_long(df, stubnames=\"y\", i=[\"code\", \"name\"], j=\"time\")\n",
    "    df = pd.DataFrame(df.to_records()).rename(index=str, columns={\"y\": \"val\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_quarter(string):\n",
    "    return string.replace(\" \", \"\").replace(\"/\", \"\").replace(\"Quarter\", \"\").replace(\"SemiAnnual\", \"2\").replace(\"Annual\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidyup_timeframe(df, is_quarter):\n",
    "    df.val = pd.to_numeric(df.val)\n",
    "    if is_quarter:\n",
    "        year_quarter = df.time.astype(str).str.extract('(.{4,4})(.{1,1})')\n",
    "        year_quarter.columns = [\"year\", \"quarter\"]\n",
    "        yq = year_quarter.year + \"-\" + year_quarter.quarter\n",
    "        yq.name = \"time\"\n",
    "        df = pd.concat([df.iloc[:, :2], yq, df.val], axis=1)\n",
    "    else:\n",
    "        year_quarter = df.time.astype(str).str.extract('(.{4,4})(.{2,2})')\n",
    "        year_quarter.columns = [\"year\", \"quarter\"]\n",
    "        yq = year_quarter.year + \"-\" + as_quarter(year_quarter.quarter).astype(str)\n",
    "        yq.name = \"time\"\n",
    "        df = pd.concat([df.iloc[:, :2], yq, df.val], axis=1)\n",
    "        df = pd.DataFrame(df.groupby([\"code\", \"name\", \"time\"]).mean().to_records())\n",
    "    df.sort_values(by=[\"code\", \"time\"], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, file_names, var_names, extension=\".xls\"):\n",
    "    dfs = []\n",
    "    for name in file_names:\n",
    "        print(name, end=\", \")\n",
    "        file_path = os.path.join(path, name+extension)\n",
    "        data = reshape_long( pd.read_excel(file_path, skiprows=5).iloc[1:, 1:] )\n",
    "        dfs.append(data)\n",
    "\n",
    "    vals = reduce(lambda x, y: x.merge(y, how=\"left\", on=[\"code\", \"name\", \"time\"]), dfs).iloc[:, 3:]\n",
    "    vals.columns = var_names\n",
    "    \n",
    "    features = extract_features(vals)\n",
    "    df = pd.concat([data.loc[:, [\"code\", \"time\"]], features], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(vals):\n",
    "    leverage = vals.leverage\n",
    "    asset_growth = vals.asset_growth\n",
    "    shares_turnover = vals.trade_amount / vals.stock_num\n",
    "    roa = vals.net_profit / vals.asset\n",
    "    roe = vals.net_profit / vals.equity\n",
    "    size = vals.market_cap\n",
    "    pcr = vals.pcr\n",
    "    per = vals.per\n",
    "    equity_turnover = vals.equity_turnover\n",
    "    volatility = vals.volatility\n",
    "    logret = np.log(vals.price).diff()\n",
    "    \n",
    "    features = pd.concat([leverage, asset_growth, shares_turnover, roa, roe, size, \n",
    "                          pcr, per, equity_turnover, volatility, logret], axis=1)\n",
    "    features.columns = [\"leverage\", \"asset_growth\", \"shares_turnover\", \"roa\", \"roe\", \"size\", \n",
    "                        \"pcr\", \"per\", \"equity_turnover\", \"volatility\", \"logret\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## `scripts/01_data-preprocessing.R` $\\rightarrow$ `scripts/01_data-preprocessing.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data\", \"raw\")\n",
    "file_names = [\"asset\", \"asset-growth\", \"equity\", \"equity-turnover\",\n",
    "              \"leverage\", \"market-cap\", \"net-profit\", \"pcr\", \"per\",\n",
    "              \"stock-number\", \"stock-price\", \"trade-amount\", \"volatility\"]\n",
    "var_names = [\"asset\", \"asset_growth\", \"equity\", \"equity_turnover\",\n",
    "             \"leverage\", \"market_cap\", \"net_profit\", \"pcr\", \"per\",\n",
    "             \"stock_num\", \"price\", \"trade_amount\", \"volatility\"]\n",
    "extension = \".xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asset, asset-growth, equity, equity-turnover, leverage, market-cap, net-profit, pcr, per, stock-number, stock-price, trade-amount, volatility, "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>time</th>\n",
       "      <th>leverage</th>\n",
       "      <th>asset_growth</th>\n",
       "      <th>shares_turnover</th>\n",
       "      <th>roa</th>\n",
       "      <th>roe</th>\n",
       "      <th>size</th>\n",
       "      <th>pcr</th>\n",
       "      <th>per</th>\n",
       "      <th>equity_turnover</th>\n",
       "      <th>volatility</th>\n",
       "      <th>logret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.850400e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.586667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.255281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-2</td>\n",
       "      <td>206.92</td>\n",
       "      <td>23.60</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>1.104880e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.053333</td>\n",
       "      <td>2.22</td>\n",
       "      <td>62.004616</td>\n",
       "      <td>0.235505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.087867e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.543333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.334550</td>\n",
       "      <td>-0.040738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000020</td>\n",
       "      <td>1997-4</td>\n",
       "      <td>324.23</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>4.613333e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.346667</td>\n",
       "      <td>2.89</td>\n",
       "      <td>62.702979</td>\n",
       "      <td>-0.847219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000020</td>\n",
       "      <td>1998-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.973333e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.726084</td>\n",
       "      <td>0.120535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code    time  leverage  asset_growth  shares_turnover       roa  \\\n",
       "0  000020  1997-1       NaN           NaN         0.006314       NaN   \n",
       "1  000020  1997-2    206.92         23.60         0.015739  0.002507   \n",
       "2  000020  1997-3       NaN           NaN         0.004035       NaN   \n",
       "3  000020  1997-4    324.23         12.41         0.004633  0.009214   \n",
       "4  000020  1998-1       NaN           NaN         0.012191       NaN   \n",
       "\n",
       "        roe          size  pcr        per  equity_turnover  volatility  \\\n",
       "0       NaN  8.850400e+10  NaN  15.586667              NaN   60.255281   \n",
       "1  0.007696  1.104880e+11  NaN  11.053333             2.22   62.004616   \n",
       "2       NaN  1.087867e+11  NaN  10.543333              NaN   56.334550   \n",
       "3  0.039088  4.613333e+10  NaN   4.346667             2.89   62.702979   \n",
       "4       NaN  5.973333e+10  NaN   4.750000              NaN   73.726084   \n",
       "\n",
       "     logret  \n",
       "0       NaN  \n",
       "1  0.235505  \n",
       "2 -0.040738  \n",
       "3 -0.847219  \n",
       "4  0.120535  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tbl = preprocess(path, file_names, var_names, extension=\".xls\")\n",
    "stock_tbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KOSPI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_df(df):\n",
    "    df = df.reset_index()\n",
    "    df[\"time\"] = df[['time', 'level_1']].astype(str).apply(lambda x: '-'.join(x), axis=1)\n",
    "    df = pd.concat([df.time, df.price], axis=1)\n",
    "    df.columns = [\"time\", \"logret\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>logret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-2</td>\n",
       "      <td>0.082477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-3</td>\n",
       "      <td>-0.064037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-4</td>\n",
       "      <td>-0.499768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-1</td>\n",
       "      <td>0.247514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time    logret\n",
       "0  1997-1       NaN\n",
       "1  1997-2  0.082477\n",
       "2  1997-3 -0.064037\n",
       "3  1997-4 -0.499768\n",
       "4  1998-1  0.247514"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi = pd.read_excel(\"data/raw/kospi-index.xlsx\", names=[\"time\", \"price\"])\n",
    "g = kospi.groupby([pd.DatetimeIndex(kospi.time).year, as_quarter(pd.DatetimeIndex(kospi.time).month)])\n",
    "g = np.log(g.mean()).diff()\n",
    "kospi = unpack_df(g)\n",
    "kospi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-1</td>\n",
       "      <td>0.119707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-2</td>\n",
       "      <td>0.118287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-3</td>\n",
       "      <td>0.119115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-4</td>\n",
       "      <td>0.145110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-1</td>\n",
       "      <td>0.204599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time         r\n",
       "0  1997-1  0.119707\n",
       "1  1997-2  0.118287\n",
       "2  1997-3  0.119115\n",
       "3  1997-4  0.145110\n",
       "4  1998-1  0.204599"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_free = pd.read_excel(\"data/raw/cd-risk-free.xlsx\", names=[\"time\", \"r\"])\n",
    "risk_free.time = risk_free.time.str.replace(\"/\", \"-\").str.split().str[0]\n",
    "risk_free.r = np.log(1 + risk_free.r / 100)\n",
    "risk_free.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.mkdir(\"data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tbl.to_csv(\"data/processed/stock2.csv\", index=False)\n",
    "kospi.to_csv(\"data/processed/kospi2.csv\", index=False)\n",
    "risk_free.to_csv(\"data/processed/risk_free2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio**\n",
    "## `src/functions-portfolio.R` $\\rightarrow$ `src/portfolio.py`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip3 install quadprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quadprog import solve_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function solve_qp in module quadprog:\n",
      "\n",
      "solve_qp(...)\n",
      "    Solve a strictly convex quadratic program\n",
      "    \n",
      "    Minimize     1/2 x^T G x - a^T x\n",
      "    Subject to   C.T x >= b\n",
      "    \n",
      "    This routine uses the the Goldfarb/Idnani dual algorithm [1].\n",
      "    \n",
      "    References\n",
      "    ---------\n",
      "    ... [1] D. Goldfarb and A. Idnani (1983). A numerically stable dual\n",
      "        method for solving strictly convex quadratic programs.\n",
      "        Mathematical Programming, 27, 1-33.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    G : array, shape=(n, n)\n",
      "        matrix appearing in the quadratic function to be minimized\n",
      "    a : array, shape=(n,)\n",
      "        vector appearing in the quadratic function to be minimized\n",
      "    C : array, shape=(n, m)\n",
      "        matrix defining the constraints under which we want to minimize the\n",
      "        quadratic function\n",
      "    b : array, shape=(m), default=None\n",
      "        vector defining the constraints\n",
      "    meq : int, default=0\n",
      "        the first meq constraints are treated as equality constraints,\n",
      "        all further as inequality constraints (defaults to 0).\n",
      "    factorized : bool, default=False\n",
      "        If True, then we are passing :math:`R^{−1}` (where :math:`G = R^T R`)\n",
      "        instead of the matrix G in the argument G.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    x : array, shape=(n,)\n",
      "        vector containing the solution of the quadratic programming problem.\n",
      "    f : float\n",
      "        the value of the quadratic function at the solution.\n",
      "    xu : array, shape=(n,)\n",
      "        vector containing the unconstrained minimizer of the quadratic function\n",
      "    iterations : tuple\n",
      "        2-tuple. the first component contains the number of iterations the\n",
      "        algorithm needed, the second indicates how often constraints became\n",
      "        inactive after becoming active first.\n",
      "    lagrangian : array, shape=(m,)\n",
      "        vector with the Lagragian at the solution.\n",
      "    iact : array\n",
      "        vector with the indices of the active constraints at the solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(solve_qp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Python`: Minimize $1/2 x^T G x - a^T x$, Subject to $C^T x >= b$.\n",
    "* `R`: $min(−d^Tb+1/2b^TDb)$ with the constraints $A^Tb>=b_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x, method, risk_free=None):\n",
    "    n_cluster = x.shape[1]\n",
    "    zeros = np.zeros(n_cluster).T\n",
    "    \n",
    "    if method == \"GMV\":\n",
    "        A = np.c_[np.ones(n_cluster), np.diag(np.ones(n_cluster))]\n",
    "        b = np.array([1] + [0]*n_cluster, dtype=np.float64)\n",
    "    elif method == \"Tangency\":\n",
    "        if not risk_free:\n",
    "            raise ValueError(\"method is 'Tangency'. 'risk_free' should not be None\")\n",
    "        rf = risk_free.r.mean()\n",
    "        A = np.c_[x.mean() - rf, np.diag([1] * n_cluster)]\n",
    "        b = np.array([(x.mean() - rf).sum(), [0] * n_cluster], dtype=np.float64)\n",
    "    else:\n",
    "        raise ValueError(\"invalid method\")\n",
    "    \n",
    "    qp = solve_qp(x.cov().to_numpy(), zeros, A, b, meq=1)\n",
    "    return qp[0]   # solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio_return(data, timeset, n_time, with_, method,\n",
    "                         market, risk_free, random_state=0):\n",
    "    p_return = np.zeros(len(timeset))\n",
    "    for i in range(len(timeset)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(*args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_portfolio(data, market, risk_free, start, end,\n",
    "                       with_list, n_time_list, method_list, random_state):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = xx.shape[1]\n",
    "qp = solve_qp(xx.cov().to_numpy(), np.zeros(n_cluster).T, \n",
    "              np.c_[np.ones(n_cluster), np.diag(np.ones(n_cluster))],\n",
    "              np.array([1] + [0]*n_cluster, dtype=np.float64), meq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14471702, 0.21681592, 0.29588222, 0.34258483])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>1.757408e+00</td>\n",
       "      <td>1.886440e-16</td>\n",
       "      <td>3.941071e-17</td>\n",
       "      <td>6.497025e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>1.886440e-16</td>\n",
       "      <td>1.173008e+00</td>\n",
       "      <td>-6.911705e-17</td>\n",
       "      <td>1.628753e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>3.941071e-17</td>\n",
       "      <td>-6.911705e-17</td>\n",
       "      <td>8.595544e-01</td>\n",
       "      <td>2.826133e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>6.497025e-17</td>\n",
       "      <td>1.628753e-16</td>\n",
       "      <td>2.826133e-16</td>\n",
       "      <td>7.423763e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1           PC2           PC3           PC4\n",
       "PC1  1.757408e+00  1.886440e-16  3.941071e-17  6.497025e-17\n",
       "PC2  1.886440e-16  1.173008e+00 -6.911705e-17  1.628753e-16\n",
       "PC3  3.941071e-17 -6.911705e-17  8.595544e-01  2.826133e-16\n",
       "PC4  6.497025e-17  1.628753e-16  2.826133e-16  7.423763e-01"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[ np.ones(3), np.diag(np.ones(n_cluster)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1] + [0]*n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "## `src/functions-clustering.R` $\\rightarrow$ `src/clustering.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_slice(data, time_idx):\n",
    "    as_list = list(time_idx)\n",
    "    return stock_tbl.groupby([\"code\"]).nth(as_list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_expand(data, skip=[0,1]):\n",
    "    cols = [col for col in range(data.shape[1]) if col not in skip]\n",
    "    \n",
    "    while len(set(data.time)) > 1:\n",
    "        lagged = data.iloc[:, cols].shift(1)\n",
    "        lagged.columns = [f\"x{c}\" for c in cols]\n",
    "        \n",
    "        data = pd.concat([data, lagged], axis=1)\n",
    "        data = data.groupby([\"code\"], as_index=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
    "        \n",
    "        cols = np.array(cols) + len(cols)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tbl(data, skip=[0,1]):\n",
    "    idx = [i for i in range(data.shape[1]) if i not in skip]\n",
    "    vals = data.iloc[:, idx]\n",
    "    data.iloc[:, idx] = (vals - vals.mean()) / vals.std()\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA에서 데이터 절반이 날아감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_(data, skip=[0,1], threshold=.8):\n",
    "    \"\"\"\n",
    "    데이터에 PCA(주성분분석)을 수행한다.\n",
    "    \n",
    "    INPUT:\n",
    "      data: data frame\n",
    "      skip: PCA 대상에서 제외할 열 번호 (integer vector)\n",
    "      threshold: 주성분 개수 선택의 기준이 되는 변동의 비율 (0 ~ 1)\n",
    "    \n",
    "    RETURN:\n",
    "      변수들이 주성분으로 대체된 data frame\n",
    "    \"\"\"\n",
    "    idx = [i for i in range(data.shape[1]) if i not in skip]\n",
    "    omit_na = data.iloc[:, idx].dropna()    #### 여기 dropna() 때문에 데이터 절반이 날아감\n",
    "    \n",
    "    pca = PCA()\n",
    "    x_pc = pd.DataFrame(pca.fit_transform(omit_na))\n",
    "    n_pc = np.where(pca.explained_variance_ratio_.cumsum() > threshold)[0][0] + 1\n",
    "    x_pc = x_pc.iloc[:, :n_pc]\n",
    "    x_pc.columns = [f\"PC{c+1}\" for c in x_pc.columns]\n",
    "    \n",
    "    df_pc = pd.concat([data.dropna().iloc[:, skip].reset_index(drop=True), x_pc], axis=1)\n",
    "    return df_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_factors_residual(data, risk_free):\n",
    "    idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "    risk_free = risk_free.iloc[idx_rf, :]\n",
    "    \n",
    "    for code in tqdm(data.code.unique()):\n",
    "        data.loc[data.code == code, \"logret\"] = data[data.code == code][\"logret\"].shift(-1)\n",
    "        data.loc[data.code == code, \"rf\"] = risk_free.r.shift(-1)\n",
    "    \n",
    "    y = data.logret - data.rf\n",
    "    x = pca_(data.drop(['logret', 'rf'], axis=1))\n",
    "    \n",
    "    df_pca = pd.concat([x, y], axis=1).iloc[:, 2:]\n",
    "    df_pca.rename(index=str, columns={0: \"y\"}, inplace=True)\n",
    "    fml = \" + \".join([c for c in df_pca.columns if \"PC\" in c])\n",
    "    lmfit = sm.OLS.from_formula(f\"y ~ {fml}\", data=df_pca).fit()\n",
    "    \n",
    "    yhat = lmfit.predict(x)\n",
    "    res = y - yhat\n",
    "    data[\"factors_res\"] = (res - res.mean()) / res.std()\n",
    "    \n",
    "    n_time = data.time.unique().shape[0]\n",
    "    dfs = [data.loc[data.code == code, :].iloc[:-1, :] for code in tqdm(data.code.unique())]\n",
    "    data = pd.concat(dfs)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_market_residual(data, market, risk_free):\n",
    "    idx_mk = [True if t in data.time.tolist() else False for t in market.time]\n",
    "    market = market.iloc[idx_mk, :]\n",
    "    \n",
    "    idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "    risk_free = risk_free.iloc[idx_rf, :]\n",
    "    \n",
    "    for code in tqdm(data.code.unique()):\n",
    "        data.loc[data.code == code, \"mk\"] = market.logret\n",
    "        data.loc[data.code == code, \"rf\"] = risk_free.r\n",
    "        y = data.logret - data.rf\n",
    "        x = data.mk - data.rf\n",
    "    \n",
    "    lmfit = sm.OLS.from_formula(\"y ~ x\", data=data).fit()\n",
    "    yhat = lmfit.predict(lmfit)\n",
    "    res = y - yhat\n",
    "    data[\"market_res\"] = (res - res.mean()) / res.std()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp(x, k, random_state=0):\n",
    "    #n = x.shape[0]\n",
    "    #centers = [0] * k\n",
    "    #centers[0] = np.random.randint(1, n+1)\n",
    "    #\n",
    "    #L2_mat = pd.DataFrame(squareform(pdist(x.iloc[:, 1:])), columns=x.index.unique(), index=x.index.unique())\n",
    "    #L2_mat = L2_mat ** 2\n",
    "    #\n",
    "    #for i in range(1, k):\n",
    "    #    weight = l2.iloc[:, centers].apply(np.min, axis=1)\n",
    "    #    centers[i] = np.random.choice(range(1, n+1), p=weight/weight.sum())\n",
    "    return KMeans(n_clusters=k, random_state=random_state).fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dunn index 대신 silhouette score를 사용\n",
    "* 속도 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_tbl(data, ncmin=2, ncmax=5):\n",
    "    data = data.dropna()\n",
    "    \n",
    "    ncs = range(ncmin, nvmax)\n",
    "    \n",
    "    X = data.iloc[:, 2:]\n",
    "    models = [kmeanspp(X, nc) for nc in ncs]\n",
    "    silhouettes = np.array([silhouette_score(X, m.labels_) for m in tqdm(models)])\n",
    "    best_model = models[silhouettes.argmax()]\n",
    "    \n",
    "    return pd.DataFrame(np.array([data.code.unique(), kmeans.labels_]).T, columns=[\"code\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_with(data, with_, market, risk_free):\n",
    "    if with_ == \"return\":\n",
    "        return data.loc[:, [\"code\", \"time\", \"logret\"]]\n",
    "    elif with_ == \"market_residual\":\n",
    "        return add_market_residual(data, market, risk_free).loc[:, [\"code\", \"time\", \"market_res\"]]\n",
    "    elif with_ == \"factors\":\n",
    "        return pca_(data.drop([\"logret\"], axis=1))\n",
    "    elif with_ == \"factors_residual\":\n",
    "        return add_factors_residual(data, risk_free).loc[:, [\"code\", \"time\", \"factors_res\"]]\n",
    "    else:\n",
    "        raise ValueError(\"'with_' should be one of ['return', 'market_residual', 'factors', 'factors_residual']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_return(return_, weight):\n",
    "    weight = np.array(weight)\n",
    "    weight = weight / weight.sum()\n",
    "    return np.log(np.sum(weight * np.exp(return_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_return_apply(row):\n",
    "    return integrate_return(row[\"logret\"], row[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_return(data, time_idx, with_, market, risk_free):\n",
    "    cluster_df = time_slice(data, time_idx)\n",
    "    cluster_df = scale_tbl(cluster_df)\n",
    "    cluster_df = kmeans_with(with_, market, risk_free)\n",
    "    cluster_df = time_expand(cluster_df)\n",
    "    cluster_df = get_kmeans_tbl(cluster_df)\n",
    "    \n",
    "    data = data.merge(cluster_df, how=\"left\", on=[\"code\"]).loc[:, [\"code\", \"time\", \"logret\", \"size\", \"cluster\"]]\n",
    "    data[\"size\"] = data.size.shift(1)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    data[\"logret\"] = data.groupby([\"cluster\", \"time\"]).apply(integrate_return_apply).reset_index(drop=True)\n",
    "    data = pd.DataFrame(pd.pivot_table(data, values='logret', index=['cluster']).T.to_records()).iloc[:, 1:]\n",
    "    data.columns = [f\"time{c}\" for c in data.columns]\n",
    "    data = data.T[0]\n",
    "    \n",
    "    x = data[time_idx]\n",
    "    y = data[time_idx[-1] + 1]\n",
    "    y_time = data.index[time_idx[-1] + 1]\n",
    "    \n",
    "    if (x.shape[0] == len(time_idx)) and (y_time == data.time.unique()[time_idx[-1]+1]):\n",
    "        return {\"x\": x, \"y\": y}\n",
    "    else:\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd = pd.DataFrame(pd.pivot_table(data, values='logret', index=['time']).T.to_records()).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd = dd.T[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.index[5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd[5:10].shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.random.randn(10).argmax()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "silhouette_score(x.iloc[:, 2:], kmeans.labels_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = pd.DataFrame([[12.654, 32.530],\n",
    "     [15.500, 12.334],\n",
    "     [14.364, 25.840],\n",
    "     [25.510, 32.224],\n",
    "     [17.636, 15.740]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l2 = pd.DataFrame(squareform(pdist(a.iloc[:, 1:])), columns=a.index.unique(), index=a.index.unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l2**2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stock_tbl = pd.read_csv(\"data/processed/stock.csv\")\n",
    "kospi = pd.read_csv(\"data/processed/kospi.csv\")\n",
    "risk_free = pd.read_csv(\"data/processed/risk_free.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = scale_tbl(stock_tbl.copy())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idx_rf = [True if t in data.time.tolist() else False for t in risk_free.time]\n",
    "risk_free = risk_free.iloc[idx_rf, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for code in tqdm(data.code.unique()):\n",
    "    data.loc[data.code == code, \"logret\"] = data[data.code == code][\"logret\"].shift(-1)\n",
    "    data.loc[data.code == code, \"rf\"] = risk_free.r.shift(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = data.logret - data.rf\n",
    "x = pca_(data.drop(['logret', 'rf'], axis=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_pca = pd.concat([x, y], axis=1).iloc[:, 2:]\n",
    "df_pca.rename(index=str, columns={0: \"y\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fml = \" + \".join([c for c in df_pca.columns if \"PC\" in c])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lmfit = sm.OLS.from_formula(f\"y ~ {fml}\", data=df_pca).fit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "yhat = lmfit.predict(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = y - yhat\n",
    "data[\"factors_res\"] = (res - res.mean()) / res.std()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_time = data.time.unique().shape[0]\n",
    "n_time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfs = [data.loc[data.code == code, :].iloc[:-1, :] for code in tqdm(data.code.unique())]\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pca(scale_tbl(stock_tbl))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vals.mean(), vals.std()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = stock_tbl.copy().head().iloc[:, :5]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "time_expand(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skip = [0,1]\n",
    "cols = [col for col in range(data.shape[1]) if col not in skip]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lagged = data.iloc[:, cols].shift(1)\n",
    "lagged.columns = [f\"x{c}\" for c in cols]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = pd.concat([data, lagged], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(set(stock_tbl.time))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "stock_tbl.groupby([\"code\"]).nth([1,2,3]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `02_main.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.clustering import *\n",
    "from src.portfolio import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_list = [\"return\", \"market_residual\", \"factors\", \"factors_residual\"]\n",
    "n_time_list = [6, 8, 10, 12]\n",
    "method_list = [\"GMV\", \"Tangency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list <- str_c(c(\"2002\", \"2005\", \"2008\", \"2011\"), \"-4\")\n",
    "end_list <- str_c(c(\"2005\", \"2008\", \"2011\", \"2014\"), \"-3\")\n",
    "valid_res_list <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = [\"2002-4\", \"2005-4\", \"2008-4\", \"2011-4\"]\n",
    "end_list = [\"2005-3\", \"2008-3\", \"2011-3\", \"2014-3\"]\n",
    "\n",
    "validation_result = []\n",
    "for i in range(4):\n",
    "    st = start_list[i]\n",
    "    en = end_list[i]\n",
    "    valid_res_list[[i]] = evaluate_portfolio(stock_tbl, kospi, risk_free, start, end,\n",
    "                                             with_list, n_time_list, method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
